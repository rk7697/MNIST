import torch
from torchvision import datasets
from PIL import Image
from torchvision import transforms
import os
import torch.nn as nn
import time
import pandas as pd
from torch.utils.data import Dataset,DataLoader
import numpy
import idx2numpy
rootdir='/Users/rk/desktop/MNIST'
traindir='/Users/rk/desktop/MNIST/train.csv'
testdir='/Users/rk/desktop/MNIST/test.csv'
trainimages=[]
trainlabels=[]
predictions=[]
device="mps" if torch.backends.mps.is_available() else "cpu"
def resizeimages():
    # (train)
    for f in os.listdir(traindir):
        ### data loading
        im=Image.open(os.path.join(traindir,f))
        im=im.resize((100,100))
        im.save(os.path.join(traindir,f),format='JPEG')
    print("resized train images")

    # (test)
    for f in os.listdir(testdir):
        ## data loading
        im=Image.open(os.path.join(testdir,f))
        im=im.resize((100,100))
        im.save(os.path.join(testdir,f),format='JPEG')
    print("resized test images")
###classes and readlabels
traindata=pd.read_csv(traindir).values
trainimages = traindata[:,1:].reshape(-1,28,28)
trainlabels=traindata[:,0]
testdata=pd.read_csv(testdir).values
testimages = testdata.reshape(-1,28,28)

###Dataset and dataloader
class customData(Dataset):
    def __init__(self,root,isTrain):
        self.isTrain=isTrain
        self.images=trainimages if isTrain else testimages
        self.labels=trainlabels if isTrain else 0
        self.root=root
    def __len__(self):
        return len(self.images)
    def __getitem__(self, indx):  
        ###image file
        im=self.images[indx]
        im=im.copy()
        ###image to tensor
        transform=transforms.ToTensor()
        im=transform(im)
        tensorimg=(torch.flatten(im).to(device)).float()/255.0
        tensorimg=tensorimg.reshape(28,28)
        ###get label
        label=self.labels[indx] if self.isTrain else -1
        label=torch.tensor(label,device=device)
        ### get file numer
        if(self.isTrain):
            return tensorimg,label
        else:
            return tensorimg, indx
        
mytrainData=customData(traindir,True)
mytestData=customData(testdir,False)
###
###Data Loaders
trainDataLoader=DataLoader(mytrainData,batch_size=32,shuffle=True)
testDataLoader=DataLoader(mytestData,batch_size=1,shuffle=False)
###
## Model class and instantiation
class network(nn.Module):
    def __init__(self):
        super().__init__()
        self.cnn1=nn.Conv2d(in_channels=1,out_channels=20,kernel_size=3,device=device)
        self.cnn2=nn.Conv2d(in_channels=20,out_channels=40,kernel_size=3,device=device)
        self.cnn3=nn.Conv2d(in_channels=40,out_channels=80,kernel_size=3,device=device)
        self.cnn4=nn.Conv2d(in_channels=80,out_channels=160,kernel_size=3,device=device)
        self.cnn5=nn.MaxPool2d(kernel_size=2)
        self.cnn6=nn.Conv2d(in_channels=160,out_channels=256,kernel_size=3,device=device)
        self.cnn7=nn.MaxPool2d(kernel_size=2)
        # self.cnn6=nn.Conv2d(in_channels=160,out_channels=160,kernel_size=3,device=device)
        # self.cnn7=nn.Conv2d(in_channels=160,out_channels=256,kernel_size=4,device=device)
        # self.cnn8=nn.MaxPool2d(kernel_size=3)
        # self.cnn9=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,device=device)
        self.linear1=nn.Linear(4*4*256,100,device=device)
        self.linear2=nn.Linear(100,100,device=device)
        self.linear3=nn.Linear(100,100,device=device)
        self.linear4=nn.Linear(100,10,device=device)
        self.activation=nn.ReLU()

    def forward(self,x):
        x=self.cnn1(x)
        x=self.activation(x)
        x=self.cnn2(x)
        x=self.activation(x)
        x=self.cnn3(x)
        x=self.activation(x)
        x=self.cnn4(x)
        x=self.activation(x)
        x=self.cnn5(x)
        x=self.cnn6(x)
        x=self.activation(x)
        x=self.cnn7(x)
        x=x.flatten()
        x=x.reshape(1,-1)
        x=self.linear1(x)
        x=self.activation(x)
        x=self.linear2(x)
        x=self.activation(x)
        x=self.linear3(x)
        x=self.activation(x)
        x=self.linear4(x)
        return x
lossfunction=nn.CrossEntropyLoss()
mynet=network()
optimizer=torch.optim.Adam(mynet.parameters(),lr=.01)
###

###training on train data with dataloader
def train(epochs):
    runningerror=0.0
    numbatches=len(trainDataLoader)
    for _ in range(epochs):
        for i, (batch, label) in enumerate(trainDataLoader):
            ###Printers
            if(i%100==99):
                print(i/numbatches)
            if(i%10000==9999):
                print("average error:{}".format(runningerror/10000.0))
                runningerror=0.0
            optimizer.zero_grad()
            ###Forward pass
            logits=mynet.forward(batch)
            loss=lossfunction(logits,label)
            ###Backward pass
            loss.backward()
            optimizer.step()
            ###Update error
            runningerror+=loss       
    print("finished training, saving model")
    torch.save(mynet.state_dict(),os.path.join(rootdir,"cnnmodelwithadam.pt"))
def test():
    global predictions
    print("testing on test data")
    mynet.load_state_dict(torch.load(os.path.join(rootdir,"cnnmodel.pt")))
    numbatches=len(testDataLoader)
    for i, (batch, indx) in enumerate(testDataLoader):
            indx=indx.item()+1
            print(i/numbatches)
            ###forward pass
            logits=mynet.forward(batch)
            ##Prediction and append
            prediction= torch.argmax(logits)
            predictions.append([indx,prediction.item()])
def writepredictions():
    global predictions
    predictions=sorted(predictions,key=lambda x: x[0])
    ###write to csv
    headers=['ImageId','Label']
    csvpath=os.path.join(rootdir,'newpredictionfile.csv')
    df=pd.DataFrame(predictions,columns=headers)
    df.to_csv(csvpath,index=False)
    print("Wrote predictions to csvfile")
train(1)
test()
writepredictions()
